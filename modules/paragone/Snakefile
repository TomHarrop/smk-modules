#!/usr/bin/env python3

from snakemake.logging import logger
import tempfile


#############
# FUNCTIONS #
#############


def resolve_input(wildcards, input):
    output_dict = {}
    for key, value in input.items():
        try:
            output_dict[key] = Path(value).resolve()
        except TypeError as e:
            logger.debug(f"Not trying to resolve {key}")
    return output_dict


def resolve_output(wildcards, output):
    output_dict = {}
    for key, value in output.items():
        try:
            output_dict[key] = Path(value).resolve()
        except TypeError as e:
            logger.debug(f"Not trying to resolve {key}")
    return output_dict


def get_paragone_input(wildcards):
    input_dict = {"paralog_sequences": paralog_sequences}
    try:
        input_dict["external_outgroups"] = external_outgroups
    except NameError:
        pass
    print(input_dict)
    return input_dict


def get_paragone_params(wildcards, input, output):
    param_dict = {"paralog_sequences": Path(input.paralog_sequences).resolve()}
    try:
        eo_path = Path(input.external_outgroups).resolve()
        of_path = Path(output.fasta).resolve()
        param_dict[
            "external_outgroups"
        ] = f"--external_outgroups_file {eo_path} "
        param_dict[
            "collect_outgroups"
        ] = f"&& mv external_outgroups_sanitised.fasta {of_path} "
    except AttributeError:
        param_dict["external_outgroups"] = ""
        param_dict["collect_outgroups"] = ""
    try:
        param_dict[
            "internal_outgroup"
        ] = f"--internal_outgroup {internal_outgroup} "
    except NameError:
        param_dict["internal_outgroup"] = ""
    print(param_dict)
    return param_dict


###########
# GLOBALS #
###########

logger.info("Paragone smk-module")

# containers
paragone = "paragone_1.0.0--pl5321h031d066_0.sif"  # FIXME
pigz = "docker://quay.io/biocontainers/pigz:2.3.4"

# catch input
paralog_sequences = config["paralog_sequences"]
logger.info(f"paralog_sequences {paralog_sequences}")

try:
    external_outgroups = config["external_outgroups"]
    logger.info(f"external_outgroups {external_outgroups}")
except KeyError as e:
    logger.warning("external_outgroups not set")

try:
    internal_outgroup = config["internal_outgroup"]
    logger.info(f"internal_outgroup {internal_outgroup}")
except KeyError as e:
    logger.warning("internal_outgroup not set")

try:
    pool = config["pool"]
    logger.info(f"pool {pool}")
except KeyError as e:
    logger.warning("pool not set, using 1")
    pool = 1

# set up directories
outdir = Path(config["outdir"] if "outdir" in config else ".")
logger.info(f"outdir: {outdir}")
logdir = Path(outdir, "logs")

# set up a temporary directory for this run
try:
    run_tmpdir = config["run_tmpdir"]
    logger.info(f"Caught run_tmpdir {run_tmpdir}")
except KeyError as e:
    logger.info(f"{e} not set in config")
    run_tmpdir = tempfile.mkdtemp()
    logger.info(f"Setting run_tmpdir to {run_tmpdir}")
    logger.warning("This probably won't work on a cluster!")

#########
# RULES #
#########


rule target:
    input:
        # ask for the tar files, otherwise they will be removed
        Path(outdir, "check_and_align.tar.gz"),
        Path(outdir, "alignment_to_tree.tar.gz"),
        Path(outdir, "qc_trees_and_extract_fasta.tar.gz"),
        Path(outdir, "align_selected_and_tree.tar.gz"),
        Path(outdir, "prune_paralogs.tar.gz"),
        Path(outdir, "final_alignments.tar.gz"),


rule final_alignments:
    input:
        mo=Path(outdir, "14_pruned_MO"),
        mi=Path(outdir, "15_pruned_MI"),
        rt=Path(outdir, "16_pruned_RT"),
        alignments=Path(outdir, "11_pre_paralog_resolution_alignments"),
    output:
        tarfile=temp(Path(run_tmpdir, "final_alignments.tar")),
        mo=directory(Path(outdir, "26_MO_final_alignments_trimmed")),
        mi=directory(Path(outdir, "27_MI_final_alignments_trimmed")),
        rt=directory(Path(outdir, "28_RT_final_alignments_trimmed")),
    params:
        resolve_input,
        resolve_output,
    log:
        Path(logdir, "final_alignments.log").resolve(),
    threads: workflow.cores // pool
    container:
        paragone
    shell:
        "workdir=$( mktemp -d ) ; "
        "cd $workdir || exit 1 ; "
        "ln -s {params[0][mo]} ./ ; "
        "ln -s {params[0][mi]} ./ ; "
        "ln -s {params[0][rt]} ./ ; "
        "ln -s {params[0][alignments]} ./ ; "
        "paragone final_alignments "
        "--mo --rt --mi "
        "--pool " + str(pool) + " "
        "--threads {threads} "
        "--keep_intermediate_files "
        "&> {log} "
        "&& "
        "mv 26_MO_final_alignments_trimmed {params[1][mo]} "
        "&& "
        "mv 27_MI_final_alignments_trimmed {params[1][mi]} "
        "&& "
        "mv 28_RT_final_alignments_trimmed {params[1][rt]} "
        "&& "
        "find . -maxdepth 1 -type l -delete "
        "&& "
        "tar -cf - . "
        "> {params[1][tarfile]} "


rule prune_paralogs:
    input:
        trees=Path(outdir, "13_pre_paralog_resolution_trees"),
        groups_list=Path(
            outdir,
            "00_logs_and_reports",
            "reports",
            "in_and_outgroups_list.tsv",
        ),
    output:
        tarfile=temp(Path(run_tmpdir, "prune_paralogs.tar")),
        mo=directory(Path(outdir, "14_pruned_MO")),
        mi=directory(Path(outdir, "15_pruned_MI")),
        rt=directory(Path(outdir, "16_pruned_RT")),
    params:
        resolve_input,
        resolve_output,
        reports_path=lambda wildcards, input: Path(input.groups_list)
        .resolve()
        .parent.parent,
    log:
        Path(logdir, "prune_paralogs.log").resolve(),
    threads: 1
    container:
        paragone
    shell:
        "workdir=$( mktemp -d ) ; "
        "cd $workdir || exit 1 ; "
        "ln -s {params.reports_path} ./ ; "
        "ln -s {params[0][trees]} ./ ; "
        "paragone "
        "prune_paralogs "
        "--mo --rt --mi "
        "&> {log} "
        "&& "
        "mv 14_pruned_MO {params[1][mo]} "
        "&& "
        "mv 15_pruned_MI {params[1][mi]} "
        "&& "
        "mv 16_pruned_RT {params[1][rt]} "
        "&& "
        "find . -maxdepth 1 -type l -delete "
        "&& "
        "tar -cf - . "
        "> {params[1][tarfile]} "


rule align_selected_and_tree:
    input:
        sequences=Path(outdir, "09_sequences_from_qc_trees"),
        alignments=Path(outdir, "04_alignments_trimmed_hmmcleaned"),
        taxon_list=Path(
            outdir,
            "00_logs_and_reports",
            "reports",
            "outgroup_taxon_list.tsv",
        ),
    output:
        trees=directory(Path(outdir, "13_pre_paralog_resolution_trees")),
        alignments=directory(
            Path(outdir, "11_pre_paralog_resolution_alignments")
        ),
        tarfile=temp(Path(run_tmpdir, "align_selected_and_tree.tar")),
        groups_list=Path(
            outdir,
            "00_logs_and_reports",
            "reports",
            "in_and_outgroups_list.tsv",
        ),
    params:
        resolve_input,
        resolve_output,
        reports_path=lambda wildcards, input: Path(input.taxon_list)
        .resolve()
        .parent.parent,
    log:
        Path(logdir, "align_selected_and_tree.log").resolve(),
    threads: workflow.cores // pool
    container:
        paragone
    shell:
        "workdir=$( mktemp -d ) ; "
        "cd $workdir || exit 1 ; "
        "ln -s {params[0][sequences]} ./ ; "
        "ln -s {params.reports_path} ./ ; "
        "paragone "
        "align_selected_and_tree "
        "{params[0][alignments]} "
        "--use_fasttree "
        "--pool " + str(pool) + " "
        "--threads {threads} "
        "&> {log} "
        "&& "
        "mv 13_pre_paralog_resolution_trees {params[1][trees]} "
        "&& "
        "mv 11_pre_paralog_resolution_alignments {params[1][alignments]} "
        "&& "
        "mv 00_logs_and_reports/reports/in_and_outgroups_list.tsv "
        "{params[1][groups_list]} "
        "&& "
        "find . -maxdepth 1 -type l -delete "
        "&& "
        "tar -cf - . "
        "> {params[1][tarfile]} "


rule qc_trees_and_extract_fasta:
    input:
        alignments=Path(outdir, "04_alignments_trimmed_hmmcleaned"),
        trees=Path(outdir, "05_trees_pre_quality_control"),
    output:
        sequences=directory(Path(outdir, "09_sequences_from_qc_trees")),
        tarfile=temp(Path(run_tmpdir, "qc_trees_and_extract_fasta.tar")),
    params:
        resolve_input,
        resolve_output,
    log:
        Path(logdir, "qc_trees_and_extract_fasta.log").resolve(),
    threads: 1
    container:
        paragone
    shell:
        "workdir=$( mktemp -d ) ; "
        "cd $workdir || exit 1 ; "
        "ln -s {params[0][trees]} ./ ; "
        "paragone "
        "qc_trees_and_extract_fasta {params[0][alignments]} "
        "--treeshrink_q_value 0.20 "
        "--cut_deep_paralogs_internal_branch_length_cutoff 0.04 "
        "&> {log} "
        "&& "
        "mv 09_sequences_from_qc_trees {params[1][sequences]} "
        "&& "
        "find . -maxdepth 1 -type l -delete "
        "&& "
        "tar -cf - . "
        "> {params[1][tarfile]} "


rule alignment_to_tree:
    input:
        alignments=Path(outdir, "04_alignments_trimmed_hmmcleaned"),
    output:
        trees=directory(Path(outdir, "05_trees_pre_quality_control")),
        tarfile=temp(Path(run_tmpdir, "alignment_to_tree.tar")),
    params:
        resolve_input,
        resolve_output,
    log:
        Path(logdir, "alignment_to_tree.log").resolve(),
    threads: workflow.cores // pool
    container:
        paragone
    shell:
        "workdir=$( mktemp -d ) ; "
        "cd $workdir || exit 1 ; "
        "paragone "
        "alignment_to_tree {params[0][alignments]} "
        "--use_fasttree "
        "--pool " + str(pool) + " "
        "--threads {threads} "
        "&> {log} "
        "&& "
        "mv 05_trees_pre_quality_control {params[1][trees]} "
        "&& "
        "tar -cf - . "
        "> {params[1][tarfile]} "


rule check_and_align:
    input:
        unpack(get_paragone_input),
    output:
        # fasta=Path(outdir, "external_outgroups_sanitised.fasta"),
        alignments=directory(Path(outdir, "04_alignments_trimmed_hmmcleaned")),
        taxon_list=Path(
            outdir,
            "00_logs_and_reports",
            "reports",
            "outgroup_taxon_list.tsv",
        ),
        tarfile=temp(Path(run_tmpdir, "check_and_align.tar")),
    params:
        get_paragone_params,
        resolve_output,
    log:
        Path(logdir, "check_and_align.log").resolve(),
    threads: workflow.cores // pool
    container:
        paragone
    shell:
        "workdir=$( mktemp -d ) ; "
        "cd $workdir || exit 1 ; "
        "paragone "
        "check_and_align {params[0][paralog_sequences]} "
        "{params[0][external_outgroups]} "
        "{params[0][internal_outgroup]} "
        "--pool " + str(pool) + " "
        "--threads {threads} "
        "&> {log} "
        # "{params[0][collect_outgroups]} "
        "&& "
        "mv 04_alignments_trimmed_hmmcleaned {params[1][alignments]} "
        "&& "
        "mv 00_logs_and_reports/reports/outgroup_taxon_list.tsv "
        "{params[1][taxon_list]} "
        "&& "
        "tar -cf - . "
        "> {params[1][tarfile]} "


rule pigz:
    input:
        Path(run_tmpdir, "{file}.tar"),
    output:
        Path(outdir, "{file}.tar.gz"),
    container:
        pigz
    threads: workflow.cores
    shell:
        "pigz -p {threads} -9 <{input} >{output}"
