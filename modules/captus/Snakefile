from functools import cache
from snakemake.logging import logger
from snakemake.exceptions import WildcardError
import re
import shutil
import tempfile


#############
# FUNCTIONS #
#############


@cache
def get_external_fastas(wildcards):
    try:
        return config["external_fasta_files"]
    except KeyError:
        logger.debug("No external_fasta_files specified")
        return []


def get_extract_inputs(wildcards):
    all_samples = get_sample_list(wildcards)
    sample_files = expand(
        Path("{sample}", "{sample}__captus-asm"),
        sample=all_samples,
    )
    return [Path(outdir, "02_assemblies", x) for x in sample_files]


@cache
def get_misc_markers(wildcards):
    try:
        return config["misc_markers"]
    except KeyError:
        logger.debug("No misc_markers specified")
        return []


def format_external_fastas(wildcards):
    external_fasta_files = get_external_fastas(wildcards)
    if external_fasta_files:
        external_fasta_paths = ",".join(
            [x.as_posix() for x in external_fasta_files]
        )
        logger.debug(f"Setting external_fasta_files to {external_fasta_paths}")
        return f"--fastas {external_fasta_paths}"
    else:
        return ""


def format_misc_markers(wildcards):
    misc_marker_files = get_misc_markers(wildcards)
    if misc_marker_files:
        misc_marker_paths = ",".join([x.as_posix() for x in misc_marker_files])
        logger.debug(f"Setting misc_markers to {misc_marker_paths}")
        return f"--dna_refs {misc_marker_paths}"
    else:
        return ""


def format_outgroup(wildcards):
    try:
        outgroup = ",".join(config["outgroup"])
    except KeyError:
        logger.debug("No outgroup specified")
        return ""
    logger.debug(f"Setting outgroup to {outgroup}")
    return f"--outgroup {outgroup}"


def get_sample_list(wildcards):
    namelist_file = checkpoints.collect_namelist.get(**wildcards).output[0]
    return read_namelist(namelist_file)


def get_wscore_cutoff(wildcards):
    try:
        minimum_sample_wscore = config["minimum_sample_wscore"]
    except KeyError:
        logger.warning("No minimum_sample_wscore specified")
        return "0.0"
    try:
        minimum_sample_wscore = float(minimum_sample_wscore)
        logger.warning(
            f"Setting minimum_sample_wscore to {minimum_sample_wscore}"
        )
    except ValueError:
        logger.warning("Checking if minimum_sample_wscore is a wildcard")
        try:
            minimum_sample_wscore = wildcards.minimum_sample_wscore
        except AttributeError as e:
            logger.warning(
                """
If you tried to set minimum_sample_wscore as a wildcard, 
make sure the wildcard is called 'minimum_sample_wscore'
                """
            )
            raise e
    return minimum_sample_wscore


@cache
def read_namelist(namelist):
    with open(namelist, "rt") as f:
        return sorted(set(x.rstrip("\n") for x in f.readlines()))


###########
# GLOBALS #
###########

# containers
bioawk = "docker://quay.io/biocontainers/bioawk:1.0--he4a0461_12"
captus = "docker://quay.io/biocontainers/captus:1.0.1--pyhdfd78af_2"
python = "docker://python:3.10.14"
r = "docker://ghcr.io/tomharrop/r-containers:r2u_24.04"

# set up directories
outdir = Path(config["outdir"] if "outdir" in config else ".")
logger.debug(f"outdir: {outdir}")
logdir = Path(outdir, "logs")
statdir = Path(outdir, "stats")

# catch samples
namelist = config["namelist"]
logger.debug(f"Caught namelist: {namelist}")

# catch read directory
read_directory = Path(config["read_directory"])
logger.debug(f"Caught read_directory: {read_directory}")

# catch target_file
target_file = Path(config["target_file"])
logger.debug(f"Caught target_file: {target_file}")

# catch options
cluster_leftovers = config.get("cluster_leftovers", True)
if cluster_leftovers:
    cluster_param = "--cluster_leftovers --mmseqs_method easy-cluster "
    extract_refs = Path(outdir, "captus-assembly_extract.refs.json.fixed")
else:
    cluster_param = ""
    extract_refs = Path(outdir, "captus-assembly_extract.refs.json")

# Captus translates the target file silently but writes it next to the input,
# so we can't pick it up as ouput from a shadow rule.
translated_targets = target_file.with_suffix(".captus.faa")


#########
# RULES #
#########


rule target:
    input:
        Path(outdir, "04_alignments"),
        extract_refs,
        Path(statdir, "captus-assembly_extract.sample_stats_by_wscore.csv"),


rule align:
    input:
        fixed_refs=extract_refs,
        extraction_dir=Path(outdir, "03_extractions"),
        failed_samples=Path(statdir, "samples_failing_filter.txt"),
    output:
        outdir=directory(Path(outdir, "04_alignments")),
    params:
        outgroup=format_outgroup,
    log:
        Path(logdir, "align.log"),
    benchmark:
        Path(logdir, "benchmark.align.log")
    threads: lambda wildcards, attempt: 16 * attempt
    resources:
        time=lambda wildcards, attempt: 120 * attempt,
        mem_mb=lambda wildcards, attempt: int(16e3 * attempt),
    shadow:
        "minimal"
    container:
        captus
    shell:
        "cp -r {input.extraction_dir} ./align_input ; "
        "while read sample; do "
        "if [ -d align_input/${{sample}}__captus-ext ]; then "
        'rm -r "align_input/${{sample}}__captus-ext" ; '
        "fi ; "
        "done < {input.failed_samples} && "
        "cp $( readlink -f {input.fixed_refs} ) "
        "align_input/captus-assembly_extract.refs.json ; "
        "captus_assembly align "
        "--captus_extractions_dir ./align_input/ "
        "--out {output.outdir} "
        '--ram "$(( {resources.mem_mb}/1000 ))" '
        "--threads {threads} "
        "{params.outgroup} "
        "&> {log}"


rule replace_temporary_paths:
    input:
        tmp_json_path=Path(outdir, "captus-assembly_extract.refs.json"),
        extraction_dir=Path(outdir, "03_extractions"),
    output:
        fixed_json=Path(outdir, "captus-assembly_extract.refs.json.fixed"),
    log:
        Path(logdir, "replace_temporary_paths.log"),
    container:
        python
    script:
        "scripts/replace_temporary_paths.py"


# lookup the median wscore for each sample and make a list of samples that
# failed
rule wscore_filter:
    input:
        sample_stats_by_wscore=Path(
            statdir, "captus-assembly_extract.sample_stats_by_wscore.csv"
        ),
    output:
        failed_samples=Path(statdir, "samples_failing_filter.txt"),
    params:
        wscore_cutoff=get_wscore_cutoff,
    container:
        bioawk
    shell:
        "awk -F, "
        "'NR == 1 {{ "
        "   for (i = 1; i <= NF; i++) {{ "
        '       if ($i == "wscore_median") wscore_col = i ; '
        '       if ($i == "marker_type") marker_col = i ; '
        "   }} "
        "}}"
        "NR > 1 "
        "&& $wscore_col < {params.wscore_cutoff} "
        '&& $marker_col == "NUC" '
        "{{ print $1 }} ' "
        "{input.sample_stats_by_wscore} "
        "> {output.failed_samples}"


rule extract_summary_stats:
    input:
        captus_extraction_dir=Path(outdir, "03_extractions"),
    output:
        sample_stats_by_wscore=Path(
            statdir, "captus-assembly_extract.sample_stats_by_wscore.csv"
        ),
        sample_stats_by_pct_recovered=Path(
            statdir,
            "captus-assembly_extract.sample_stats_by_pct_recovered.csv",
        ),
    params:
        captus_extraction_stats=Path(
            outdir, "03_extractions", "captus-assembly_extract.stats.tsv"
        ).as_posix(),
    log:
        Path(
            logdir,
            "extract_summary_stats.log",
        ),
    container:
        r
    script:
        "scripts/extract_summary_stats.R"


rule extract:
    input:
        assemblies=get_extract_inputs,
        external_fasta_files=get_external_fastas,
        misc_markers=get_misc_markers,
        target_file=target_file,
    output:
        outdir=directory(Path(outdir, "03_extractions")),
        refs_json=Path(outdir, "captus-assembly_extract.refs.json"),
    params:
        cluster_param=cluster_param,
        external_fastas=format_external_fastas,
        misc_markers=format_misc_markers,
    log:
        Path(logdir, "extract.log"),
    benchmark:
        Path(logdir, "benchmark.extract.log")
    threads: lambda wildcards, attempt: 16 * attempt
    resources:
        time=lambda wildcards, attempt: 120 * attempt,
        mem_mb=lambda wildcards, attempt: int(16e3 * attempt),
    shadow:
        "minimal"
    container:
        captus
    shell:
        "mkdir ./extract_input && "
        "for assembly in {input.assemblies}; do "
        'ln -s $( readlink -f $assembly ) "$(pwd)/extract_input/" ; '
        "done && "
        "captus_assembly extract "
        "--captus_assemblies_dir ./extract_input "
        "{params.external_fastas} "
        "{params.misc_markers} "
        "--out {output.outdir}/. "
        "--nuc_refs {input.target_file} "
        "--mit_refs SeedPlantsMIT "
        "--ptd_refs SeedPlantsPTD "
        "{params.cluster_param} "
        '--ram "$(( {resources.mem_mb}/1000 ))" '
        "--threads {threads} "
        "&> {log} "
        "; mv {output.outdir}/captus-assembly_extract.refs.json "
        "{output.refs_json}"


rule assemble:
    input:
        r1=Path(outdir, "reads", "{sample}_R1.fastq.gz"),
        r2=Path(outdir, "reads", "{sample}_R2.fastq.gz"),
    output:
        outdir=directory(
            Path(outdir, "02_assemblies", "{sample}", "{sample}__captus-asm")
        ),
    params:
        outdir=lambda wildcards, output: Path(output.outdir).parent,
    log:
        Path(logdir, "assemble", "{sample}.log"),
    benchmark:
        Path(logdir, "assemble", "benchmark.{sample}.log")
    threads: lambda wildcards, attempt: 16 * attempt
    resources:
        time=lambda wildcards, attempt: 120 * attempt,
        mem_mb=lambda wildcards, attempt: int(16e3 * attempt),
    shadow:
        "minimal"
    container:
        captus
    shell:
        "captus_assembly assemble "
        "--reads {input.r1} {input.r2} "
        "--out {params.outdir} "
        '--tmp_dir "$( mktemp -d )" '
        '--ram "$(( {resources.mem_mb}/1000 ))" '
        "--threads {threads} "
        "&> {log}"


# this rule only runs if the reads aren't named as Captus expects.
rule collect_reads:
    input:
        Path(read_directory, "{sample}.r{read}.fastq.gz"),
    output:
        temp(Path(outdir, "reads", "{sample}_R{read}.fastq.gz")),
    shell:
        "ln -s "
        '"$( readlink -f {input} )" '
        '"$( readlink -f {output} )" '


# This HAS to be a checkpoint. We need to read this file to know which samples
# we have.
checkpoint collect_namelist:
    input:
        namelist,
    output:
        Path(outdir, "namelist.captus.txt"),
    shell:
        "(cat {input} && echo) > {output}"
