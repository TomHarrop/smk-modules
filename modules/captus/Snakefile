#!/usr/bin/env python3

import re
import tempfile
from snakemake.logging import logger
from functools import cache

#############
# FUNCTIONS #
#############


@cache
def sample_name_sanitiser(sample_name):
    if re.compile("[^a-zA-Z0-9_-]").search(sample_name):
        raise ValueError(f"{sample_name} contains special character(s)")


###########
# GLOBALS #
###########

# containers
captus = "docker://quay.io/biocontainers/captus:1.0.1--pyhdfd78af_2"

# set up directories
outdir = Path(config["outdir"] if "outdir" in config else ".")
logger.debug(f"outdir: {outdir}")
logdir = Path(outdir, "logs")

# catch samples
all_samples = config["sample_list"]
logger.debug(f"Caught samples: {all_samples}")

# check sample names
for sample in all_samples:
    sample_name_sanitiser(sample)


wildcard_constraints:
    sample="[a-zA-Z0-9_-]+",
    read=[1, 2],


# catch read directory
read_directory = Path(config["read_directory"])
logger.debug(f"Caught read_directory: {read_directory}")

# catch target_file
target_file = Path(config["target_file"])
logger.debug(f"Caught target_file: {target_file}")

# captus outputs
statsfiles = [
    "captus-assembly_align.alignments",
    "captus-assembly_align.paralogs",
    "captus-assembly_align.samples",
]
# alignment_dirs = expand(
#     Path(
#         outdir,
#         "04_alignments",
#         "03_trimmed",
#         "06_informed",
#         "{locus_type}",
#         "{alignment_type}",
#     ),
#     alignment_type=[
#         "01_AA",
#         "02_NT",
#         "03_genes",
#     ],
#     locus_type=["01_coding_NUC", "03_coding_MIT"],
# )


#########
# RULES #
#########

# target is defined at the bottom of the workflow


rule align:
    input:
        multiext(
            Path(
                outdir, "03_extractions", "captus-assembly_extract"
            ).as_posix(),
            ".log",
            ".refs.json",
            ".report.html",
            ".stats.tsv",
        ),
        extrs=expand(
            Path(outdir, "03_extractions", "{sample}__captus-ext"),
            sample=all_samples,
        ),
        clustering_data=Path(outdir, "03_extractions", "02_clustering_data"),
    output:
        # directory(alignment_dirs),
        stats=expand(
            Path(outdir, "04_alignments", "{statsfile}.tsv"),
            statsfile=statsfiles,
        ),
        report=Path(
            outdir, "04_alignments", "captus-assembly_align.report.html"
        ),
        my_outdir=directory(Path(outdir, "04_alignments")),
    params:
        extrs=lambda wildcards, input: Path(input.extrs[0]).parent,
        my_outdir=lambda wildcards, output: Path(output.my_outdir),
    log:
        Path(logdir, "align.log"),
    benchmark:
        Path(logdir, "benchmark.align.log")
    threads: lambda wildcards, attempt: 16 * attempt
    resources:
        time=lambda wildcards, attempt: 120 * attempt,
        mem_mb=lambda wildcards, attempt: int(16e3 * attempt),
    shadow:
        "minimal"
    container:
        captus
    shell:
        "captus_assembly align "
        "--captus_extractions_dir {params.extrs} "
        "--out {params.my_outdir} "
        '--ram "$(( {resources.mem_mb}/1000 ))" '
        "--threads {threads} "
        "&> {log}"


rule extract:
    input:
        asms=expand(
            Path("05_extract-input", "{sample}__captus-asm"),
            sample=all_samples,
        ),
        target_file=target_file,
    output:
        multiext(
            Path(
                outdir, "03_extractions", "captus-assembly_extract"
            ).as_posix(),
            ".log",
            ".refs.json",
            ".report.html",
            ".stats.tsv",
        ),
        outdir=directory(
            expand(
                Path(outdir, "03_extractions", "{sample}__captus-ext"),
                sample=all_samples,
            ),
        ),
        clustering_data=directory(
            Path(outdir, "03_extractions", "02_clustering_data")
        ),
    shadow:
        "minimal"
    params:
        asms=lambda wildcards, input: Path(input.asms[0]).parent,
        outdir=lambda wildcards, output: Path(output.outdir[0]).parent,
    log:
        Path(logdir, "extract.log"),
    benchmark:
        Path(logdir, "benchmark.extract.log")
    threads: lambda wildcards, attempt: 16 * attempt
    resources:
        time=lambda wildcards, attempt: 120 * attempt,
        mem_mb=lambda wildcards, attempt: int(16e3 * attempt),
    container:
        captus
    shell:
        "captus_assembly extract "
        "--captus_assemblies_dir {params.asms} "
        "--out {params.outdir} "
        "--nuc_refs {input.target_file} "
        "--mit_refs SeedPlantsMIT "
        "--cluster_leftovers "
        "--mmseqs_method easy-cluster "
        '--ram "$(( {resources.mem_mb}/1000 ))" '
        "--threads {threads} "
        "&> {log}"
        " ; tree"


rule collect_assemblies:
    input:
        Path(outdir, "02_assemblies", "{sample}", "{sample}__captus-asm"),
    output:
        temp(directory(Path("05_extract-input", "{sample}__captus-asm"))),
    shell:
        "ln -s "
        '"$( readlink -f {input} )" '
        '"$( readlink -f {output} )" '


rule assemble:
    input:
        r1=Path("reads", "{sample}_R1.fastq.gz"),
        r2=Path("reads", "{sample}_R2.fastq.gz"),
    output:
        outdir=directory(
            Path(outdir, "02_assemblies", "{sample}", "{sample}__captus-asm")
        ),
    shadow:
        "minimal"
    params:
        outdir=lambda wildcards, output: Path(output.outdir).parent,
    log:
        Path(logdir, "assemble", "{sample}.log"),
    benchmark:
        Path(logdir, "assemble", "benchmark.{sample}.log")
    threads: lambda wildcards, attempt: 16 * attempt
    resources:
        time=lambda wildcards, attempt: 120 * attempt,
        mem_mb=lambda wildcards, attempt: int(16e3 * attempt),
    container:
        captus
    shell:
        "captus_assembly assemble "
        "--reads {input.r1} {input.r2} "
        "--out {params.outdir} "
        '--tmp_dir "$( mktemp -d )" '
        '--ram "$(( {resources.mem_mb}/1000 ))" '
        "--threads {threads} "
        "&> {log}"


rule collect_reads:
    input:
        Path(read_directory, "{sample}.r{read}.fastq.gz"),
    output:
        temp(Path("reads", "{sample}_R{read}.fastq.gz")),
    shell:
        "ln -s "
        '"$( readlink -f {input} )" '
        '"$( readlink -f {output} )" '


rule target:
    input:
        rules.extract.output,
        rules.align.output,
    default_target: True
